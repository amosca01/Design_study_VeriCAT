\section{Quantitative Evaluation} 

In this experiment, we test whether VeriCAT improves users' ability to identify Russian $\rightarrow$ English translated text that is untrustworthy.    
%with scores generated by DA \remco{what is DA?} (which we consider ground-truth), and with scores generated by OpenKiwi's predictor-estimator QE \remco{is this the same as VeriCat QE?}.
We run this evaluation via a crowdsourced study for two reasons. (1) We did not have additional access to analysts for testing. And (2) our hope is that VeriCAT's utility extends past analysts to general users of MT technologies (ex. users of Facebook's translate feature, or users of Google Translate).     
The following sections outline the study in more detail. 

%\subsection{Explanation Techniques}
\subsection{Experimental Conditions}

For this experiment we test VeriCAT against a baseline condition, and against a Beta version of VeriCAT. This results in a 3 condition between-subjects experiment. 

In the baseline condition, participants are shown a passage of original Russian text broken into sentences, and the corresponding MT. No additional information is provided to the participant, hence we call this condition No XAI for short. In the VeriCAT condition, participants use VeriCAT (Figure \ref{fig:p3_predicted_quality}) to perform the experimental task. In the Beta VeriCAT condition, participants use the VeriCAT interface, but instead of showing QE scores the interface shows direct assessment (DA) scores of the translated text (Figure \ref{fig:p1_human_quality}). When referring to conditions we distinguish between VeriCAT and Beta VeriCAT with the short hand Predicted Quality (for VeriCAT's QE scores), and Human Quality (for Beta VeriCAT which shows DA scores). 

\ab{Andrea, how do you feel about this naming? Should re do the rest with No XAI, VeriCAT, and Beta VeriCAT?}  
 
We include the Human Quality condition because in the event that VeriCAT fails to improve participants' performance, we want to determine if this is due to the lack of variance in QE scores or if showing participants quality estimates for MT text fails in all cases (even if scores are based on human-generated ground truth). 

%  \remco{this setup is a little weird. This experimental setup seems to be tested something theoretical, but not about the effectiveness of VeriCat. If you're testing VeriCat, wouldn't the conditions be: (1) VeriCat, (2) no VeriCat, and (3) human translation  (i.e. ground truth)?}

\subsection{Passage Type}
We postulate that without XAI users will rely on fluency as a proxy for translation quality. Prior work shows that this is the case when it comes to trust of MT \cite{martindaleFluency2018}. However, there are cases where this technique fails as described in Section \ref{sec:design_requirements}.  
Each sentence in a passage can fall into one of four categories: (1) \textit{poor fluency + poor quality}, (2) \textit{poor fluency + good quality}, (3) \textit{good fluency + poor quality}, (4) \textit{good fluency + good quality}. Of these, we expect  sentences in the \textit{good fluency + poor quality}, and \textit{poor fluency + good quality} categories to be the most difficult for participants to assess. To test if these different sentence types have an effect on participants’ performance we arrange two different types of passages described below: 

\begin{compacthang}
    \item \textbf{Type 1} \textit{Good fluency + good quality, good fluency + poor quality, poor fluency + good quality}. Passage 1 is of this type and is shown in Figure \ref{fig:p1_human_quality}.    

    \item \textbf{Type 2} \textit{Good fluency + good quality, poor fluency + good quality, poor fluency + poor quality}. Passage 3 is of this type and is shown in Figure \ref{fig:p3_predicted_quality}.     
\end{compacthang}

Both of these passage types are designed to test if participants in an XAI condition will heed quality scores or their own intuition based on fluency to identify poor quality translations. 

\begin{figure}
    \centering
    
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{p1_v_0.png} 
        \caption{Passage 1 (passage type 1), Human Quality condition} \label{fig:p1_human_quality}
    \end{subfigure}
    \hfill
     \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{p3_p_0.png} 
        \caption{Passage 3 (passage type 2), Predicted Quality condition} \label{fig:p3_predicted_quality}
    \end{subfigure}
    
    \caption{Select examples of stimuli. All stimuli are available in supplemental materials.}
    \label{fig:exp_stim}
    
\end{figure}

\subsection{Task} 
We run a 3 condition experiment: No XAI, Human Quality, and Predicted Quality. Within each condition we include 2 passages of type 1 followed by 2 of type 2. The experimental task replicates an analyst determining if a MT needs a human translation as closely as possible within a controlled setting. 

For each of four passages of text participants are shown the passage broken into three sentences. Each sentence is shown in the original Russian and as a MT. Participants in the Quality conditions would additionally see a quality score for each sentence (Figure \ref{fig:exp_stim}). Participants are instructed to decide if any of the sentences in the passage should be re-translated by a human, and given the chance to select sentence 1, 2, or 3 of the passage for re-translation by a human, or no-retranslation. After their selection, the original passage and machine translation remained on the screen in addition to the human translation of whichever sentence they selected for re-translation. At this point participants were asked to answer two information retrieval questions. 
 %The prompt before each passage is as follows:

%\begin{quote}
%Below is a passage written in Russian with an English translation generated by artificial intelligence. When you are ready, you will be asked to answer two comprehension questions. \textbf{You may select up to one section of the passage for re-translation by a human.} We recommend selecting the section you judge to have the poorest machine translation for re-translation by a human. 

%Click ``I’m ready to see the questions'' when you are ready to see the comprehension questions. \textbf{If you would like a human re-translation of any section of the passage you must request it BEFORE you click ``I’m ready to see the questions''.} Once you click ``I’m ready to see the questions'', comprehension questions will appear on the page alongside the Russian test, English Machine translation, and any human translations you requested.  
%\end{quote}


\begin{table}[]
\resizebox{0.60\textwidth}{!}{%
\begin{tabular}{c|c|c}
\hline
\begin{tabular}[c]{@{}c@{}}Human Quality Score \\ (Human Quality)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Predicted Quality Score \\ (Predicted Quality)\end{tabular} &  \begin{tabular}[c]{@{}c@{}}No XAI\\ (No XAI)\end{tabular} \\ \hline
                                                                    59                                                                       & 59                                                                                         & 47                                                        \\ \hline
\end{tabular}
}
\caption{N for each condition. }
\label{tab:exp_N}
\end{table}

\subsection{Participants} 

We recruited 193 participants from Amazon Mechanical Turk. Participation was restricted to
workers in the United States with an approval rating of greater than 90 percent who do not speak Russian or Ukranian. Participants were paid a base rate of USD $1.60$ for participation. Before analysis, participants who answered information retrieval questions for passage 1 and passage 2 (attention check questions) incorrectly were dropped from analysis ($N = 28$).  This left $N = 165$ participants distributed among stimuli as shown in Table \ref{tab:exp_N}. Demographics of participants are shown in Table \ref{tab:exp_demo}.


\begin{table}[h!]
\begin{threeparttable}[b]
\begin{tabular}{ll}
\hline
N                                                                                & 165                                                                                                                                                    \\ \hline
Age                                                                              & \begin{tabular}[c]{@{}l@{}}18-24: 6.7\%, 25-34: 45.5\%, 35-44: 24.8\%, \\ 45-54: 14.5\%, 55-64: 7.3\%, 65+: 1.2\%\end{tabular}                                     \\ \hline
Gender                                                                           & \begin{tabular}[c]{@{}l@{}}Female: 38.2\%, Male: 61.2\%, Non-binary: 0.6\%\end{tabular}                                                             \\ \hline
Education                                                                        & \begin{tabular}[c]{@{}l@{}}High School: 13.3\%, Associates: 12.1\%, Bachelors: 60.0\%, \\ Masters: 11.5\%, Professional: 2.4\%, Doctorate: 0.6\%\end{tabular}                            \\ \hline
\end{tabular}
\end{threeparttable}
\caption{Participant demographics.}
\label{tab:exp_demo}
\end{table}

\subsection{Procedure}

The experiment followed an approved protocol per \textit{redacted\_for\_anonymity}’s company policy, and was posted as a HIT on Amazon Mechanical Turk. Workers who accepted the HIT followed a link to the experiment. After providing informed consent, participants were taken to an instruction page explaining the experiment. This page explained that they would see 4 passages of text translated from Russian to English by AI. They were told that they would be asked to answer two comprehension questions for each passage, but before doing so would have the opportunity to see one of the sentences in the passage re-translated by a human. After the instruction page, participants were shown the four passages one at a time. Participants could take as much time with each stimulus as they wanted before clicking a button to select which section of the passage they wanted re-translated and viewing the passage questions. After completing the main task, participants were asked to complete a short post-experiment questionnaire, the Tolerance for Ambiguity Survey from Geller et al. 1993 \cite{gellerTolerance1993}, a short demographic questionnaire, and to provide any additional feedback they wished.

\subsection{Hypotheses}

%We postulate that providing quality estimations for each sentence will help participants identify the sentence of lowest quality for re-translation only in cases where there is a significant difference between scores. In other words, we expect participants in the Human Quality condition to perform significantly better than participants in the Predicted Quality condition. 

We evaluate VeriCAT with DA vs. QE scores, and with respect t our design requirements (Section \ref{sec:design_requirements}). To gather a more nuanced understanding of how individual users may or may not benefit from our approach to explaining MT we also test a number of hypotheses based on individual user differences. 


\begin{compacthang}
    \item \textbf{H1}: Participants in the quality score conditions will have higher accuracy in identifying which sentence in a passage is of low quality and should be re-translated than participants in the baseline condition. 
    \item \textbf{H2}: Participants in the quality score conditions will have a greater change in trust of machine translation than participants in the baseline condition. 
    \item \textbf{H3}: Participants’ tolerance for ambiguity will correlate with how well they are able to use the VeriCAT to perform the experimental task.
    \item \textbf{H4}: Participants’ experience using machine translation will correlate with how well they are able to use VeriCAT to perform the experimental task.
    \item \textbf{H5}: Participants’ self-rated expertise in AI, MT, visualization, and statistics will correlate with how well they are able to use VeriCAT to perform the experimental task.   
\end{compacthang}

\subsection{Findings}

We consider a participant’s answer correct if they select the sentence in a passage with the lowest quality score as the one to get re-translated by a human. To calculate overall accuracy, we sum the number of correct answers across all four passages and divide by 4. The following analyses use this outcome measure to test the hypotheses listed above. Analysis scripts and de-identified data are available in supplemental materials. 

\subsubsection{\textbf{Does VeriCAT help?}}

We start by looking at which sentences people chose to re-translate for each condition and passage. For all passages, we see participants quality score conditions are on average most accurate at selecting the correct sentence for re-translation. Interestingly, we see that participants in the No XAI condition often opt for no-retranslation. Proportions of participants giving each answer for each passage and condition are shown in Figure \ref{fig:exp_prop_answers}.

\begin{figure}*
    \centering
    
    \cbox{bar-noXai} \textit{No XAI} \quad
    \cbox{bar-Qual} \textit{Human Quality} \quad
    \cbox{bar-PredictQ} \textit{Predicted Quality} \quad
    
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{
        \begin{bchart}[step=.25,max=1,width=\linewidth]
        \bcbar[color=bar-noXai]{.06}
        \bclabel{\textit{Good Fluency}}
        \bcbar[color=bar-Qual]{.51}
        \bclabel{\textit{Poor score}}
        \bcbar[color=bar-PredictQ]{.37}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.15}
        \bclabel{\textit{Good Fluency}}
        \bcbar[color=bar-Qual]{.15}
        \bclabel{\textit{Good score}}
        \bcbar[color=bar-PredictQ]{.07}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.38}
        \bclabel{\textit{Poor Fluency}}
        \bcbar[color=bar-Qual]{.14}
        \bclabel{\textit{Good score}}
        \bcbar[color=bar-PredictQ]{.31}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.40}
        \bclabel{\textit{No}}
        \bcbar[color=bar-Qual]{.20}
        \bclabel{\textit{Re-translation}}
        \bcbar[color=bar-PredictQ]{.25}
        
        \bcxlabel{Proportion of Participants Selecting}
        \end{bchart}}
        \caption{Passage 1} 
        \label{fig:exp_p1_prop_answers}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{
        \begin{bchart}[step=.25,max=1,width=\linewidth]
        \bcbar[color=bar-noXai]{.06}
        \bclabel{\textit{Good Fluency}}
        \bcbar[color=bar-Qual]{.53}
        \bclabel{\textit{Poor score}}
        \bcbar[color=bar-PredictQ]{.37}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.13}
        \bclabel{\textit{Good Fluency}}
        \bcbar[color=bar-Qual]{.12}
        \bclabel{\textit{Good score}}
        \bcbar[color=bar-PredictQ]{.08}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.21}
        \bclabel{\textit{Poor Fluency}}
        \bcbar[color=bar-Qual]{.15}
        \bclabel{\textit{Good score}}
        \bcbar[color=bar-PredictQ]{.20}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.60}
        \bclabel{\textit{No}}
        \bcbar[color=bar-Qual]{.20}
        \bclabel{\textit{Re-translation}}
        \bcbar[color=bar-PredictQ]{.34}
        
        \bcxlabel{Proportion of Participants Selecting}
        \end{bchart}}
        \caption{Passage 2} 
        \label{fig:exp_p2_prop_answers}
    \end{subfigure}
    \hfill
     \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{
        \begin{bchart}[step=.25,max=1,width=\linewidth]
        \bcbar[color=bar-noXai]{.26}
        \bclabel{\textit{Poor Fluency}}
        \bcbar[color=bar-Qual]{.69}
        \bclabel{\textit{Poor score}}
        \bcbar[color=bar-PredictQ]{.68}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.19}
        \bclabel{\textit{Poor Fluency}}
        \bcbar[color=bar-Qual]{.05}
        \bclabel{\textit{Good score}}
        \bcbar[color=bar-PredictQ]{.15}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.09}
        \bclabel{\textit{Good Fluency}}
        \bcbar[color=bar-Qual]{.10}
        \bclabel{\textit{Good score}}
        \bcbar[color=bar-PredictQ]{.03}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.47}
        \bclabel{\textit{No}}
        \bcbar[color=bar-Qual]{.15}
        \bclabel{\textit{Re-translation}}
        \bcbar[color=bar-PredictQ]{.14}
        
        \bcxlabel{Proportion of Participants Selecting}
        \end{bchart}}
        \caption{Passage 3} 
        \label{fig:exp_p3_prop_answers}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{
        \begin{bchart}[step=.25,max=1,width=\linewidth]
        \bcbar[color=bar-noXai]{.45}
        \bclabel{\textit{Poor Fluency}}
        \bcbar[color=bar-Qual]{.64}
        \bclabel{\textit{Poor score}}
        \bcbar[color=bar-PredictQ]{.64}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.02}
        \bclabel{\textit{Poor Fluency}}
        \bcbar[color=bar-Qual]{.12}
        \bclabel{\textit{Good score}}
        \bcbar[color=bar-PredictQ]{.08}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.11}
        \bclabel{\textit{Good Fluency}}
        \bcbar[color=bar-Qual]{.10}
        \bclabel{\textit{Good score}}
        \bcbar[color=bar-PredictQ]{.12}
        \bcskip{6pt}
        
        \bcbar[color=bar-noXai]{.43}
        \bclabel{\textit{No}}
        \bcbar[color=bar-Qual]{.14}
        \bclabel{\textit{Re-translation}}
        \bcbar[color=bar-PredictQ]{.15}
        
        \bcxlabel{Proportion of Participants Selecting}
        \end{bchart}}
        \caption{Passage 4} 
        \label{fig:exp_p4_prop_answers}
    \end{subfigure}
    
    \caption{Proportions of participants selecting each type of sentence for re-translation by passage.}
    \label{fig:exp_prop_answers}

\end{figure}

To test if the differences we observe are significant we run a Kruskal-Wallis test of $overall\_score \sim condition$ \footnote{We use a Kruskal-Wallis test because according to the Shapiro-Wilk Normality test $overall\_score$ is not normally distributed ($W = 0.87, p < 0.001$).} and find a significant difference across conditions ($H(2) = 29.7, p < 0.001$). A post-hoc Dunn’s multiple comparisons test with a Bonferroni corrected alpha ($0.02$) shows significant pairwise differences between Human Quality and No XAI ($Z = 5.2, p < 0.01$), and No XAI and Predicted Quality ($Z = -4.3, p < 0.01$). Figure \ref{fig:exp_overall_distribution} shows $overall\_score$ distributions by condition. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.50\textwidth]{exp2_overall_distribution.png}
    \caption{Boxplot of overall score by condition.}
    \label{fig:exp_overall_distribution}
\end{figure}

These results suggest that sentence-level quality scores can significantly improve participants’ performance over No XAI, regardless of if they are ground-truth or model predictions. Therefore, we \textbf{accept H1}. The results also show that there is no significant difference in performance between ground-truth and predicted quality scores, suggesting that though imperfect, QE scores are as effective as DA quality scores. 

\subsubsection{\textbf{Does VeriCAT affect trust?}}

We ask participants before the experimental task: “Please rate how much you trust artificial intelligence to correctly translate sentences from a language you do not speak into a language you do speak from 1 (No trust) to 5 (Complete trust).”  We ask the same question at the end of the experiment. To analyze whether different conditions changed participants' trust in machine translation, we calculate $delta\_trust$ for each participant by subtracting their answer to the pre-experimental task trust question from their answer to the post-experimental task trust question. 

We run a Kruskal-Wallis test of $delta\_trust \sim condition$ \footnote{We use a Kruskal-Wallis test because according to the Shapiro-Wilk Normality test $delta\_trust$ is not normally distributed ($W = 0.74, p < 0.001$).} and find no significant difference across conditions ($H(2) = 3.5, p = 0.17$). This suggests that neither the presence of XAI nor the different types of quality scores significantly affected participants’ trust in machine translation, thus we \textbf{reject H2}. Average change in trust by condition is shown in Figure \ref{fig:exp_delta_trust}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.50\textwidth]{exp2_delta_trust.png}
    \caption{Boxplot of change in trust by condition.}
    \label{fig:exp_delta_trust}
\end{figure}

\subsubsection{\textbf{Is the efficacy of VeriCAT influenced by participants' individual differences?}}

Prior work has shown that individual user differences can play a strong role in how well users utilize a visualization for a problem solving task\cite{liuSurvey2020}. However, there has been little research investigating how individual differences can affect understanding, trust, and use of AI. In an effort to start answering this question we captured three different individual differences of users (intolerance for ambiguity, usage of MT, and self-rated expertise) and analysed whether there were any correlations between these measures and users’ $overall\_score$. Our findings follow.

\paragraph{\textbf{Does intolerance of ambiguity affect performance?}} 

Given the survey instrument we use to measure Intolerance for Ambiguity\cite{gellerTolerance1993} participants’ scores could range from 7 (extremely low intolerance for ambiguity) to 49 (extremely high intolerance for ambiguity). The median score for intolerance for ambiguity of participants is 30. 

To determine if there could be a linear relationship between participants' $overall_score$ and $intolerance\_for\_ambiguity$, we tested for a significant Pearson correlation between the two within each condition. Regression lines for each condition are shown in Figure \ref{fig:exp_intol_ambiguity}. We find no significant correlation in any condition (Human Quality -- ($r(57) = -0.14, p = 0.29$), Predicted Quality --  ($r(57) = 0.03, p = 0.81$), No XAI -- ($r(45) = -0.01, p = 0.95)$), and thus do not perform any linear regressions. This suggests that intolerance for ambiguity has no effect on participants' performance, thus we \textbf{reject H3}. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.50\textwidth]{exp2_intol_ambiguity.png}
    \caption{Regression lines of overall score and intolerance for ambiguity by condition.}
    \label{fig:exp_intol_ambiguity}
\end{figure}

\paragraph{\textbf{Does regular usage of machine translation affect performance?}}

We ask participants to rank how often they use Google Translate and Facebook Translate on a five-point scale of Never, Yearly, Monthly, Weekly, Daily. We assign weights to each point on the scale ranging from 1 (Never) to 5 (Daily) and use these to calculate a machine translation usage score for each participant. The higher this score, the more often a participant indicated using MT. 

To determine if there could be a linear relationship between participants' $overall_score$ and $MT_usage$, we tested for a significant Pearson correlation between the two within each condition.
Regression lines for each condition are shown in Figure \ref{fig:exp_MT_use}. We find a significant correlation between frequency of MT usage and overall score for participants in the Human Quality condition ($r(57) = -0.32, p < 0.05$), and no significant correlation in any other condition (Predicted Quality -- ($r(57) = -0.21, p = 0.11$), No XAI -- ($r(45) = -0.23, p = 0.11$)). We run a linear regression for the Human quality condition and find a significant effect between $overall_score$ and $MT_usage$ ($F(1, 57) = 6.4, p < .05, R^2 = 0.10$), with $MT_usage$ as a significant predictor ($t = -2.54, p < 0.05$). This suggests that in the Human Quality condition as participants’ frequency of MT usage increases, their performance decreases, thus we \textbf{partially accept H4}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.50\textwidth]{exp2_MT_use.png}
    \caption{Regression lines of overall score and frequency of MT usage by condition.}
    \label{fig:exp_MT_use}
\end{figure}

\paragraph{\textbf{Does participants' self-rated expertise affect performance?}}

We ask participants to rate their own expertise from 1 (Novice) to 5 (Expert) in four areas related to XAI: AI, MT, visualization, and statistics. 

To determine if there could be a linear relationship between participants' $overall_score$ and $expertise$, we tested for a significant Pearson correlation between the two within each condition. Regression lines for each condition are shown in Figure \ref{fig:exp_expert}.
In the Human Quality, and Predicted Quality conditions we find a significant correlations between self rated expertise in AI and MT and $overall\_score$. In addition, we find significant correlations between self-rated expertise in visualization and statistics and overall score in the Predicted Quality condition.  
(Analysis results for all of these tests are listed in Table \ref{tab:exp1_expertise_stats}.) Overall, our results suggest that in all cases except for No XAI as self-rated expertise in AI and MT (and in the case of Predicted Quality visualization and statistics) increase, $overall\_score$ decreases, thus we \textbf{accept H5}.

\begin{figure}[h!]
    \centering
    
    \cbox{bar-noXai} \textit{No XAI} \quad
    \cbox{bar-Qual} \textit{Human Quality} \quad
    \cbox{bar-PredictQ} \textit{Predicted Quality} \quad
    
    \includegraphics[width=0.50\textwidth]{exp2_expert.png}
    \caption{Regression lines of overall score and self-rated expertise by condition.}
    \label{fig:exp_expert}
\end{figure}

\begin{table}[]
\resizebox{0.70\textwidth}{!}{%
\begin{tabular}{llcc}
\hline
\multicolumn{1}{c}{Measure}                            & \multicolumn{1}{c}{Condition} & Result & Regression    \\ \hline
\multirow{4}{*}{Self-rated expertise in AI}            & Human Quality              & $\mathbf{r(57) = -0.27, p < 0.05}$ & 
$\mathbf{F(1, 57) = 4.39, p < 0.05, R^2 = 0.07; t = -2.10, p < 0.05}$  \\
                                                       & Predicted Quality          & $\mathbf{r(57) = -0.29, p < 0.05}$ & 
$\mathbf{F(1, 57) = 5.24, p < 0.05, R^2 = 0.08; t = -2.29, p < 0.05}$         \\
                                                       & No XAI                     & $r(45) = 0.02, p = 0.91$                     \\ \hline
\multirow{4}{*}{Self-rated expertise in MT}            & Human Quality              & $\mathbf{r(57) = -0.31, p < 0.05}$ & 
$\mathbf{F(1, 57) = 6.26, p < 0.05, R^2 = 0.10; t = -2.50, p < 0.05}$ \\
                                                       & Predicted Quality          & $\mathbf{r(57) = -0.40, p < 0.01}$ & 
$\mathbf{F(1, 57) = 10.55, p < 0.01, R^2 = 0.16; t = -3.25, p < 0.01}$          \\
                                                       & No XAI                     & $r(45) = -0.13, p = 0.39$                    \\ \hline
\multirow{4}{*}{Self-rated expertise in visualization} & Human Quality              & $r(57) = -0.24, p = 0.06$                    \\
                                                       & Predicted Quality          & $\mathbf{r(57) = -0.31, p < 0.05}$ & 
$\mathbf{F(1, 57) = 6.18, p < 0.05, R^2 = 0.10; t = -2.49, p < 0.05}$                  \\
                                                       & No XAI                     & $r(45) = -0.11, p = 0.48$                    \\ \hline
\multirow{4}{*}{Self-rated expertise in statistics}    & Human Quality              & $r(57) = -0.21, p = 0.10$                    \\
                                                       & Predicted Quality          & $\mathbf{r(57) = -0.36, p < 0.01}$ & 
$\mathbf{F(1, 57) = 8.75, p < 0.01, R^2 = 0.13; t = -2.96, p < 0.01}$          \\
                                                       & No XAI                     & $r(45) = -0.11, p = 0.46$                    \\ \hline
\end{tabular}%
}
\caption{Pearson correlation results for each self-rated expertise measure by condition. Significant results are in \textbf{bold}, and regression results are included.}
\label{tab:exp1_expertise_stats}
\end{table}

\subsection{\textbf{Qualitative Feedback}}

Qualitative feedback from our study indicated that overall users were satisfied with VeriCAT. A random sampling of participants were asked if they would have liked to see any additional information, and only 5 of the 66 participants asked this question said yes. Overall, we gathered very positive feedback from study participants. Many commented that it was a ``good" and ``interesting" study, and one participant (who was assigned to a quality score condition) went as far to say ``the task was enjoyable". This feedback indicates that VeriCAT performs its intended purpose well, and does so without negatively effecting participants.       

\subsection{Discussion} 

The purpose this experiment is to test if showing users of MT text sentence-level quality scores of translations can improve performance in identifying poor quality machine translations. We find that both DA and QE scores significantly improve user performance compared to No XAI. 
In addition, we find that although user performance is slightly lower with machine-generated QE scores, there is no significant difference in performance compared to ground-truth DA scores. 

Unexpectedly, we find providing quality scores has no effect on participants' trust of MT. There are a few potential explanations for this. One is that participants in general come into the experiment with an appropriate amount of trust in MT quality. In this case, showing participants quality estimation for MT would help them perform the experimental task more accurately, but would not necessarily reveal to them that MT is less (or more) accurate than they already expected it to be. 

Another explanation could be that our experimental task is not realistic enough to force users to consider their trust of MT output. Future work should explore a similar study in which the experimental task comes at more of a stake to the user. For example, asking the user to flag sentences as inappropriate based on MT, or asking the user whether or not they would re-post a passage based on the MT. Scenarios such as these may elicit a stronger evaluation of trust from participants.

Unlike participants in the Human Quality condition, we find no significant correlation between participants' overall score and frequency of MT use in the Predicted Quality condition. Similar to the Human Quality condition, we find a significant negative correlation between participants' self-rated expertise in AI and MT and overall score in the Predicted Quality condition.  

This finding is surprising, as we would expect people who are more familiar with MT through frequent usage to have a better understanding of its limitations and similarly we would expect people with more expertise in MT and AI to have a good understanding of MT limitations and of how to read and process quality indicators. We postulate that in both of these cases what we are observing is overconfidence leading to errors. We suspect that the more often one uses MT, the more the more familiar and comfortable they become with it and therefore see no need to rely on quality scores instead of themselves to identify poor translations. We suspect that the same is true of self-rated experts in MT and AI, and the better someone thinks they are at understanding the underlying mechanisms of MT the more likely they are to want to rely on their own quality assessments instead of those shown by VeriCAT.

Our findings suggest that novices are likely to follow XAI guidance, while those with more familiarity or expertise in the area are likely to ignore XAI guidance in favor of their own judgement. This means that in designing XAI interfaces, designers should pay specific attention to this population and center their design around the unique needs of these users instead of complete novices. 

Finally, our findings suggest that although the QE model is not perfect it currently performs well enough to be used as a part of MT XAI, and doing so will not introduce any additional burdens to different types of users. In fact, utilizing QE scores instead of DA scores may remove the potentially negative effect of prior MT usage on performance.  



\section{Conclusion}

In this paper, we describe the design, development and evaluation of the user interface (UI) for the VeriCAT system, a tool that combines a Machine Translation (MT) Quality Estimation (QE) model with a simple-to-use interface. The purpose of the VeriCAT UI is to help analysts understand the limitations of machine translation and determine whether or not MT text should be verified by a human before being acted upon. Based on conversations with experts, we determined a UI for MT text must \ab{insert some version of design guidelines}. The VeriCAT UI satisfies these requirements via sentence-level QE scores generated by the VeriCAT Model, which predicts  the translation quality of sentences translated from Russian into English with the FairSeq MT model. We evaluate the VeriCAT UI with a quantitative user study that measures how the tool impacts usersâ€™ ability to identify poor quality MT text. Our evaluation shows the UI is useful for its intended purpose, and validates that VeriCAT QE scores perform as well as human ground-truth quality scores. Finally, we provide lessons learned from this study for future work in this space to leverage.


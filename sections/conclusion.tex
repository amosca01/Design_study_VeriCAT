\section{Conclusion}

Because human translators are limited, intelligence analysts can find themselves dependant on machine translations of text in order to do their jobs. However, MT is not perfect, and acting on miss-translations has led to adverse events in the past. In this paper we present VeriCAT, an XAI tool built to help analysts understand the limitations of machine translation so that they can determine whether or not MT text should be verified by a human before being acted upon. Based on conversations with experts and analysts, we identify four design requirements that guide the development of VeriCAT. The VeriCAT system combines a Machine Translation (MT) Quality Estimation (QE) model which predicts the translation quality of sentences translated from Russian into English with the FairSeq MT model with a simple-to-use interface. In the VeriCAT UI sentence-level QE scores are shown alongside MT text. We evaluate VeriCAT with a quantitative user study that measures how the tool impacts usersâ€™ ability to identify poor quality MT text. Our evaluation shows VeriCAT significantly improves participants' accuracy in identifying poor quality machine translated text, and that participants assigned to QE scores perform as well as those assigned to ground-truth human-generated quality scores. 


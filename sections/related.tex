\section{Related Work}

Despite the growing ubiquity of MT, there is little research either on communicating the output of MT to end users, or on how visualization may help with this communication.  
To set the stage for out work, we provide high-level summaries of existing work in MT QE and in visualization for MT.  

\subsection{Machine Translation Quality Estimation} 
The study of MT began in the 1950's, but it was not until recently that significant advances greatly improved MT accuracy and usability. Despite these advances, however, human translators still outperform MT in overall accuracy and in preserving the original meaning of translated text\cite{mauvcec2019machine}. As use of MT becomes more widespread, problems can arise when translations are inaccurate. One way to address this problem is by using a second machine learning model to predict the quality of the MT model's output.  

There are many ways to evaluate MT quality. Numerous automatic metrics aim to approximate human judgement including: BLEU, NIST, METEOR, and TER\cite{mauvcec2019machine}. Additionally, there are some human-in-the-loop automatic judgements. For instance, HTER (human-mediated translation error rate)  attempts to capture the number of post edits made to a MT by a human translator\cite{mauvcec2019machine} and human judgements of translation fluency and adequacy\cite{snover2009Fluency} can be captured via a Direct Assessment (DA) score. While certain metrics are only appropriate for document-level quality assessment, others can be used to train a QE model to predict the quality of specific sentences. HTER and DA have previously been used to train sentence-level QE models~\cite{turchi2014adaptive, graham_baldwin_moffat_zobel_2017}.            

While many advancements have been made in MT QE, few efforts have studied how usable these tools are or how they might impact a user's ability to make decisions based on perceived translation quality. OpenKiwi \cite{UnBabel} performed a demo of a user interface for QE at ACL 2019; however, the team has not released their code, a demo, or a user study. There are also few tools designed to make QE accessible to non-MT experts. Avramidis created a GUI for this purpose; however, it still requires that users are proficient in Python and the command line\cite{avramidis2017QE}.    

At the IUI conference in 2020 researchers presented a demonstration titled: \textit{XAIT: An Interactive Website for Explainable AI for Text}. We reviewed the papers cited by this work and found that none of them related specifically to MT usability \cite{oduor2020XAIT}. In fact, the only usability study we found for MT was one by Martindale and Carpuat, which investigates how revealing MT errors in fluency and adequacy might change users' trust in MT. This work finds that poor fluency in translations can significantly influence users' trust of MT, but that trust is easily rebuilt\cite{martindaleFluency2018}.       

\subsection{Visualization and Machine Translation}

Though MT is becoming more widespread, there are few tools designed to help users understand its reliability. At the time of writing this paper we are aware of only one tool besides ours built to meet this need: Collins et al.'s lattice visualization, which illustrates uncertainty in MT text. While Collins et al. demonstrate that this method is effective for an instant messaging scenario~\cite{collins2007lattices}, we doubt its ability to scale to a use case involving full passages of text.  

Albrecht et al.'s human-AI collaborative system uses visualization to help users gain intuition about a translation's source language so that they may correct errors in MT text~\cite{albrecht2009chinese}. And DeNeefe et al. developed an interactive translation visualization tool called a DerivTool, which is intended to give users intuition about the MT model itself~\cite{deneefe2005interactively}. In contrast to these approaches, which emphasize source language or the underlying MT model itself, VeriCAT is distinct in that it provides contextual information about when and whether users should trust the output of MT, i.e. a particular snippet of MT text. 

%An area in which there is particular overlap between visualization and MT is the Digital Humanities. In this setting, the goal of visualization and MT is typically to enable comparisons of one text in several languages~\cite{janicke2017visual}. For example, ShakerVis is a tool for comparing different translations of \textit{Othello}~\cite{geng2015shakervis}. This work is similar to our in that the goal is making MT text more usable to users, however it differs significantly in  

%Our work differs from  
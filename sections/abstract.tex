\section{Abstract}

%Explainable AI (XAI) tools and research efforts seek to provide insight about “black box” AI/ML systems. Many of these efforts, however, overlook the UI/UX (user interface / user experience) aspects of this challenge. Extracting the right information from and about models is crucial, but it is only part of the challenge of explainability; this information must also be presented to someone through an effective interface.

In this paper, we describe the design, development and evaluation of the user interface (UI) for VeriCAT, a tool that combines a Machine Translation (MT) Quality Estimation (QE) model with a simple-to-use interface. The purpose of the VeriCAT UI is to help users understand the limitations of machine translation and determine whether or not to trust a specific machine translated sentence. VeriCAT predicts the translation quality of sentences translated from Russian into English with the FairSeq MT model, and its UI shows users sentence-level QE scores for translated passages of text. We evaluate the UI with a quantitative user study that measures how the tool impacts users’ ability to perform a human-AI collaborative task. Our evaluation shows the UI is useful for its intended purpose. Finally, we provide lessons learned from this study for future work in this space to leverage.  

%suggest ways in which future work can leverage our UI evaluation to iterate on VeriCAT as an XAI system system. 

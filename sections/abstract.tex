\section{Abstract}

In this paper, we describe the design, development, and evaluation of VeriCAT, a system that predicts the quality of machine translated text. Miss-translation by AI has led to adverse effects in the past, such as erroneous arrests. VeriCAT is designed to address this issue. Short for verification of computer-assisted translation, VeriCAT predicts a sentence-level quality score for individual snippets of Russian text that have been translated into English. The VeriCAT user interface displays these sentence-level quality scores, along with the original and translated text, in order to help users determine whether to trust a specific machine-translated sentence. We evaluate VeriCAT with a quantitative user study to measure how the tool impacts participants’ ability to identify poor quality MTs, and find the tool significantly increases participants’ accuracy on this task. Moreover, we find participants perform the task as accurately with VeriCAT QE scores as with ground truth quality scores.
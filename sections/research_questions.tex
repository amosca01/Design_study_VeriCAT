\section{Research Questions}

Our main focus in developing the VeriCAT system is to help users more appropriately use MT text. In short, our hope is that a tool like the VeriCAT system can help prevent erroneous situations such as the Facebook “good morning” arrest explained in Section \ref{sec:use_case}. Ideally, in the Facebook situation there would have been some XAI to communicate that the MT text was likely of low quality, and that XAI would have been effective for a wide demographic of end users. Moreover, the XAI would give end users a healthy skepticism of MT, as opposed destroying their trust in it or making them overly trusting of it. Our goal in designing the VeriCAT system was to create an XAI that achieves these goals. Therefore, in evaluating it we are guided by the following research questions:     

\begin{compacthang}
    \item \textbf{RQ1}: Does adding an XAI interface to Russian > English Machine Translations help users identify poorly translated sentences that should be checked by a human better than they could by relying on fluency? 
    
    \item \textbf{RQ2}:  Does providing an XAI interface to Russian > English Machine Translations change users’ trust in Machine Translation? 
    
    \item \textbf{RQ3}: Do individual user differences, such as tolerance for ambiguity, experience using Machine Translation, or prior expertise, affect how helpful the XAI interface is?
\end{compacthang}



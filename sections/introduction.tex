\section{Introduction}

In 2017 Facebook's machine translation (MT) algorithm incorrectly translated a construction worker's Arabic-language post. The original post said ``good morning" in Arabic, but was erroneously translated into Hebrew as ``attack them", leading to the worker's arrest and several hours of questioning. Notably, no Arabic-speakers were asked to verify the machine translation of the post leading up to the arrest~\cite{hernFacebook2017}. For many users of machine translation, it is easy to forget that translated output is susceptible to error and, as illustrated by this situation, some translation errors can lead to severe consequences.
%Analysts might use machine translation in situations where human translators are in short supply. To avoid potentially negative consequences of erroneous translations, analysts would benefit from tools that help them  
%asses the quality of specific passages of translated text.  
Our goal in this work is to develop and evaluate a tool to help users determine when, and whether, to trust machine translation. 

To that end, we present and evaluate VeriCAT, which stands for Verification of Computer-Assisted Translation. VeriCAT is designed to help those using machine translation assess the quality of translated text. In particular, we focus on text snippets that have been translated from Russian into English by the FairSeq model ~\cite{ott-etal-2019-fairseq}. 
VeriCAT consists of a Quality Estimation (QE) model combined with an easy-to-use interface. The objective of QE is to train a machine learning model to predict a quality score for translated text that is similar to what a human would assign to that translation~\cite{mauvcec2019machine}. VeriCAT's QE model is a trained version of OpenKiwiâ€™s predictor-estimator model \cite{Kim2017PredictorEstimatorUM}. VeriCAT's interface shows users the output of the QE model -- a predicted quality score (some value out of a possible 100) for individual sentences of machine-translated text (Figure \ref{fig:p3_predicted_quality}).

VeriCAT is novel in using the output of a Quality Estimation model to provide context to MT users. Typically, QE is used by developers of MT models for validation and model improvement. However, we believe predicted quality scores can also benefit users of translated text, by helping them determine when and whether to trust a particular machine translated sentence. While many MT accuracy metrics (such as BLEU score \cite{papineni-etal-2002-bleu}) provide information about the accuracy of a MT model in general, QE serves as a metric for \textit{individual sentences}. 
 
We evaluate VeriCAT with a quantitative user study, where users are asked to perform an analogous task to that which motivates the development of VeriCAT. Participants see a passage of text translated from Russian $\rightarrow$ to English via the FairSeq model~\cite{ott-etal-2019-fairseq}. They are informed that they will be asked to answer two comprehension questions based on the text, and are given the opportunity to request a human translation of any (or none) of the sentences in the passage before seeing the comprehension questions. We advise participants to select the sentence with the poorest quality translation to be re-translated and we score participants based on whether they actually choose the lowest quality translation, which is measured by a human-generated Direct Assessment score. %\andrea{add sentence explaining DA score}

Our study shows that participants who have access to VeriCAT's quality scores more frequently select the lowest quality translation (i.e. they perform better on the user study task), compared to participants who do not. Moreover, we find correlations between participants' familiarity with MT tools and self-rated expertise in AI and MT, and their performance on the task. 

In the following sections we describe the design of VeriCAT, briefly explaining the QE model behind the system and the evaluation of the system as a whole. In summary, we contribute the following: 

\begin{enumerate}
    \item The VeriCAT system, which uses quality estimation (QE) to help users decide if and when to trust sentences of machine translated text.   
    \item An evaluation of VeriCAT, demonstrating (1) that its quality scores significantly improve participants' performance in identifying poor quality machine translations, and (2) that VeriCAT's predicted quality scores perform as well as human-generated quality scores (which we treat as ground-truth). 
    \item Evidence that individual differences between participants may effect how much they benefit from VeriCAT's quality scores. 
\end{enumerate}

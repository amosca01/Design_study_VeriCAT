@article{martindaleFluency2018,
  author    = {Marianna J. Martindale and
               Marine Carpuat},
  title     = {Fluency Over Adequacy: A Pilot Study in Measuring User Trust in Imperfect MT},
  journal   = {CoRR},
  volume    = {abs/1802.06041},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.06041},
  archivePrefix = {arXiv},
  eprint    = {1802.06041},
  timestamp = {Mon, 13 Aug 2018 16:48:27 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1802-06041.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{gellerTolerance1993,
 ISSN = {00257079},
 URL = {http://www.jstor.org/stable/3766298},
 author = {Gail Geller and Ellen S. Tambor and Gary A. Chase and Neil A. Holtzman},
 journal = {Medical Care},
 number = {11},
 pages = {989--1001},
 publisher = {Lippincott Williams \& Wilkins},
 title = {Measuring Physicians' Tolerance for Ambiguity and Its Relationship to Their Reported Practices regarding Genetic Testing},
 volume = {31},
 year = {1993}
}

@article{liuSurvey2020,
  title={Survey on Individual Differences in Visualization},
  author={Liu, Zhengliang and Crouser, R Jordan and Ottley, Alvitta},
  journal={arXiv preprint arXiv:2002.07950},
  year={2020}
}

@online{OECDurl,
  author = { },
  title = {OECD Principles on AI},
  year = 2020,
  url = {https://www.oecd.org/going-digital/ai/principles/},
  urldate = {2020-08-28}
}

@online{OECDrecommendationsurl,
  author = {OECD Council on Artificial Intelligence},
  title = {OECD Legal Instruments, Recommendation of the Council on Artificial Intelligence},
  year = 2019,
  url = {https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449},
  urldate = {2020-08-31}
}

@online{FannieMaeurl,
  author = {Tracy Stephan},
  title = {How Will Artificial Intelligence Shape Mortgage Lending?},
  year = 2018,
  url = {https://www.fanniemae.com/portal/research-insights/perspectives/artificial-intelligence-mortgage-lending-stephan-100418.html},
  urldate = {2020-08-28}
}

@online{Recidivismurl,
  author = {Mirilla Zhu},
  title = {An Algorithmic Jury: Using Artificial Intelligence to Predict Recidivism Rates},
  year = 2020,
  url = {https://www.yalescientific.org/2020/05/an-algorithmic-jury-using-artificial-intelligence-to-predict-recidivism-rates/},
  urldate = {2020-08-28}
}

@online{PredictiveHireurl,
  author = { },
  title = {PredictiveHire company website},
  year = 2020,
  url = {https://www.predictivehire.com/},
  urldate = {2020-08-28}
}

@article{hernFacebook2017, 
    title={Facebook translates 'good morning' into 'attack them', leading to arrest},
    url={https://www.theguardian.com/technology/2017/oct/24/facebook-palestine-israel-translates-good-morning-attack-them-arrest}, 
    journal={The Guardian}, 
    author={Hern, Alex}, 
    year={2017}, 
    month={Oct}
}

@inproceedings{brennen2020What, 
    author = {Brennen, Andrea}, 
    title = {What Do People Really Want When They Say They Want "Explainable AI?" We Asked 60 Stakeholders.}, year = {2020}, 
    isbn = {9781450368193}, 
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA}, 
    url = {https://doi.org/10.1145/3334480.3383047}, 
    doi = {10.1145/3334480.3383047}, 
    booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
    pages = {1–7}, 
    numpages = {7}, 
    keywords = {user research, interface design, UI/UX design, machine learning, data science, explainable AI}, 
    location = {Honolulu, HI, USA}, 
    series = {CHI EA '20} 
}

@article{MillerHoweInmates2017,
  author    = {Tim Miller and
               Piers Howe and
               Liz Sonenberg},
  title     = {Explainable {AI:} Beware of Inmates Running the Asylum Or: How {I}
               Learnt to Stop Worrying and Love the Social and Behavioural Sciences},
  journal   = {CoRR},
  volume    = {abs/1712.00547},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.00547},
  archivePrefix = {arXiv},
  eprint    = {1712.00547},
  timestamp = {Thu, 25 Apr 2019 14:47:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-00547.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@online{DARPAXAI,
  author = {Gunning, David and Turek, Matt},
  title = {Defense Advanced Research Projects Agency Program Information: Explainable Artificial Intelligence (XAI)},
  year = 2016,
  url = {https://www.darpa.mil/program/explainable-artificial-intelligence},
  urldate = {2020-09-01}
}

@inproceedings{RiberoLIME2016,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
pages = {1135–1144},
numpages = {10},
keywords = {interpretability, black box classifier, interpretable machine learning, explaining machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@InProceedings{KimTCAV2018,
  title = 	 {Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors ({TCAV})},
  author =       {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and sayres, Rory},
  pages = 	 {2668--2677},
  year = 	 {2018},
  editor = 	 {Jennifer Dy and Andreas Krause},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/kim18d/kim18d.pdf},
  url = 	 {http://proceedings.mlr.press/v80/kim18d.html},
}

@incollection{LundbergLeeSHAP2017,
title = {A Unified Approach to Interpreting Model Predictions},
author = {Lundberg, Scott M and Lee, Su-In},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4765--4774},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf}
}

@misc{vaughanXNN2018,
    title={Explainable Neural Networks based on Additive Index Models},
    author={Joel Vaughan and Agus Sudjianto and Erind Brahimi and Jie Chen and Vijayan N. Nair},
    year={2018},
    eprint={1806.01933},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@article{WachterCounterfactual2017,
   title={Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR},
   ISSN={1556-5068},
   url={http://dx.doi.org/10.2139/ssrn.3063289},
   DOI={10.2139/ssrn.3063289},
   journal={SSRN Electronic Journal},
   publisher={Elsevier BV},
   author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
   year={2017}
}

@article{SelbstBarocasIntuitive2018,
author = {Selbst, Andrew and Barocas, Solon},
year = {2018},
month = {01},
pages = {},
title = {The Intuitive Appeal of Explainable Machines},
volume = {87},
journal = {Fordham Law Review, SSRN Electronic Journal},
doi = {10.2139/ssrn.3126971}
}

@article{MittelstadtRussellExplain2019,
   title={Explaining Explanations in AI},
   ISBN={9781450361255},
   url={http://dx.doi.org/10.1145/3287560.3287574},
   DOI={10.1145/3287560.3287574},
   journal={Proceedings of the Conference on Fairness, Accountability, and Transparency - FAT*  ’19},
   publisher={ACM Press},
   author={Mittelstadt, Brent and Russell, Chris and Wachter, Sandra},
   year={2019}
}

@misc{rudin2018stop,
    title={Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
    author={Cynthia Rudin},
    year={2018},
    eprint={1811.10154},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{herman2017promise,
    title={The Promise and Peril of Human Evaluation for Model Interpretability},
    author={Bernease Herman},
    year={2017},
    eprint={1711.07414},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@article{DoshiVelezAccountability2017,
   title={Accountability of AI Under the Law: The Role of Explanation},
   ISSN={1556-5068},
   url={http://dx.doi.org/10.2139/SSRN.3064761},
   DOI={10.2139/ssrn.3064761},
   journal={SSRN Electronic Journal},
   publisher={Elsevier BV},
   author={Doshi-Velez, Finale and Kortz, Mason and Budish, Ryan and Bavitz, Christopher and Gershman, Samuel J. and O’Brien, David and Shieber, Stuart and Waldo, Jim and Weinberger, David and Wood, Alexandra},
   year={2017}
}

@book{FriedmanElements2001,
  author    = {Friedman, J. and Hastie, T. and Tibshirani, R.}, 
  title     = {The elements of statistical learning},
  publisher = {Springer},
  year      = 2001,
  volume    = 1,
  series    = 10,
  isbn      = { }
}

@book{HallGill2018,
  author    = {Hall, P. and Gill, N.}, 
  title     = {Introduction to Machine Learning Interpretability},
  publisher = {O'Reilly Media, Incorporated},
  year      = 2018,
  isbn      = { }
}

@misc{bastani2017interpreting,
    title={Interpreting Blackbox Models via Model Extraction},
    author={Osbert Bastani and Carolyn Kim and Hamsa Bastani},
    year={2017},
    eprint={1705.08504},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@online{PoursabziManipulating2018,
  author = {Forough Poursabzi},
  title = {Manipulating and measuring model interpretability},
  year = 2018,
  url = {https://www.slideshare.net/SessionsEvents/manipulating-and-measuring-model-interpretability},
  urldate = {2020-09-01}
}

@misc{adebayo2018sanity,
    title={Sanity Checks for Saliency Maps},
    author={Julius Adebayo and Justin Gilmer and Michael Muelly and Ian Goodfellow and Moritz Hardt and Been Kim},
    year={2018},
    eprint={1810.03292},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}